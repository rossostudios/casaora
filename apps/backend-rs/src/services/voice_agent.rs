use serde_json::{json, Value};

use crate::{
    error::{AppError, AppResult},
    state::AppState,
};

/// Orchestrate a voice agent interaction using TTS (ElevenLabs) + STT (Whisper) + agent loop.
/// This is called from the Twilio webhook route when an incoming call is received.
pub async fn handle_voice_interaction(
    state: &AppState,
    org_id: &str,
    caller_phone: &str,
    audio_url: Option<&str>,
) -> AppResult<Value> {
    let pool = state.db_pool.as_ref().ok_or_else(|| {
        AppError::Dependency("Database is not configured.".to_string())
    })?;

    // 1. Look up caller in guest/tenant records
    let caller_info: Option<(String, String)> = sqlx::query_as(
        "SELECT id::text, full_name FROM guests
         WHERE organization_id = $1::uuid AND phone = $2
         LIMIT 1",
    )
    .bind(org_id)
    .bind(caller_phone)
    .fetch_optional(pool)
    .await
    .ok()
    .flatten();

    let (guest_id, caller_name) = caller_info.unwrap_or_default();

    // 2. If audio provided, transcribe with Whisper
    let transcript = if let Some(url) = audio_url {
        transcribe_audio(state, url).await.unwrap_or_default()
    } else {
        String::new()
    };

    // 3. Route to appropriate agent based on transcript content
    let agent_slug = classify_voice_intent(&transcript);

    // 4. Log the voice interaction
    let mut msg = serde_json::Map::new();
    msg.insert(
        "organization_id".to_string(),
        Value::String(org_id.to_string()),
    );
    msg.insert("channel".to_string(), Value::String("voice".to_string()));
    msg.insert(
        "recipient".to_string(),
        Value::String(caller_phone.to_string()),
    );
    msg.insert(
        "direction".to_string(),
        Value::String("inbound".to_string()),
    );
    msg.insert("status".to_string(), Value::String("received".to_string()));
    let mut payload = serde_json::Map::new();
    payload.insert("body".to_string(), Value::String(transcript.clone()));
    payload.insert(
        "guest_id".to_string(),
        Value::String(guest_id.clone()),
    );
    payload.insert(
        "caller_name".to_string(),
        Value::String(caller_name.clone()),
    );
    payload.insert(
        "routed_to_agent".to_string(),
        Value::String(agent_slug.to_string()),
    );
    msg.insert("payload".to_string(), Value::Object(payload));
    let _ = crate::repository::table_service::create_row(pool, "message_logs", &msg).await;

    Ok(json!({
        "ok": true,
        "caller_phone": caller_phone,
        "caller_name": caller_name,
        "guest_id": guest_id,
        "transcript": transcript,
        "routed_to_agent": agent_slug,
    }))
}

/// Transcribe audio using OpenAI Whisper API.
async fn transcribe_audio(state: &AppState, audio_url: &str) -> Result<String, String> {
    let api_key = state
        .config
        .openai_api_key
        .as_deref()
        .filter(|s| !s.is_empty())
        .ok_or_else(|| "OPENAI_API_KEY not configured".to_string())?;

    // Download audio
    let audio_bytes = state
        .http_client
        .get(audio_url)
        .timeout(std::time::Duration::from_secs(30))
        .send()
        .await
        .map_err(|e| format!("Failed to download audio: {e}"))?
        .bytes()
        .await
        .map_err(|e| format!("Failed to read audio bytes: {e}"))?;

    let base_url = state.config.openai_api_base_url.trim_end_matches('/');
    let whisper_url = format!("{base_url}/v1/audio/transcriptions");

    let part = reqwest::multipart::Part::bytes(audio_bytes.to_vec())
        .file_name("audio.wav")
        .mime_str("audio/wav")
        .map_err(|e| format!("Multipart error: {e}"))?;

    let form = reqwest::multipart::Form::new()
        .text("model", "whisper-1")
        .text("language", "es")
        .part("file", part);

    let response = state
        .http_client
        .post(&whisper_url)
        .header("Authorization", format!("Bearer {api_key}"))
        .multipart(form)
        .timeout(std::time::Duration::from_secs(30))
        .send()
        .await
        .map_err(|e| format!("Whisper API request failed: {e}"))?;

    let body: Value = response
        .json()
        .await
        .map_err(|e| format!("Failed to parse Whisper response: {e}"))?;

    Ok(body
        .get("text")
        .and_then(Value::as_str)
        .unwrap_or_default()
        .to_string())
}

/// Classify voice intent to route to appropriate agent.
fn classify_voice_intent(transcript: &str) -> &'static str {
    let lower = transcript.to_lowercase();
    if lower.contains("maintenance")
        || lower.contains("repair")
        || lower.contains("broken")
        || lower.contains("mantenimiento")
        || lower.contains("roto")
    {
        "maintenance-triage"
    } else if lower.contains("payment")
        || lower.contains("rent")
        || lower.contains("pago")
        || lower.contains("alquiler")
    {
        "finance-agent"
    } else if lower.contains("lease")
        || lower.contains("contract")
        || lower.contains("contrato")
    {
        "leasing-agent"
    } else if lower.contains("guest")
        || lower.contains("check-in")
        || lower.contains("huÃ©sped")
    {
        "guest-concierge"
    } else {
        "supervisor"
    }
}

/// Generate TTS audio response using ElevenLabs.
pub async fn generate_voice_response(
    state: &AppState,
    text: &str,
) -> Result<Vec<u8>, String> {
    let api_key = state
        .config
        .elevenlabs_api_key
        .as_deref()
        .filter(|s| !s.is_empty())
        .ok_or_else(|| "ELEVENLABS_API_KEY not configured".to_string())?;

    let voice_id = state
        .config
        .elevenlabs_voice_id
        .as_deref()
        .unwrap_or("21m00Tcm4TlvDq8ikWAM"); // Default voice

    let url = format!(
        "https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    );

    let response = state
        .http_client
        .post(&url)
        .header("xi-api-key", api_key)
        .json(&json!({
            "text": text,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.75,
            }
        }))
        .timeout(std::time::Duration::from_secs(30))
        .send()
        .await
        .map_err(|e| format!("ElevenLabs API failed: {e}"))?;

    if !response.status().is_success() {
        return Err(format!("ElevenLabs API returned {}", response.status()));
    }

    response
        .bytes()
        .await
        .map(|b| b.to_vec())
        .map_err(|e| format!("Failed to read TTS audio: {e}"))
}
